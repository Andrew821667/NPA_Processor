"""
GPT –ø–æ–º–æ—â–Ω–∏–∫ –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –∏–∑ –Ω–µ—Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞
–ò—Å–ø–æ–ª—å–∑—É–µ—Ç OpenAI API –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —Ç–µ–∫—Å—Ç–∞ –∏ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è —Å–ø–∏—Å–∫–∞ –ù–ü–ê
"""

import json
import time
from typing import List, Dict, Any
import openai

class GPTHelper:
    def __init__(self, api_key: str, model: str = "gpt-4o-mini"):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è GPTHelper —Å —É–ª—É—á—à–µ–Ω–∏—è–º–∏
        
        Args:
            api_key: OpenAI API –∫–ª—é—á
            model: –ú–æ–¥–µ–ª—å GPT (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é gpt-4o-mini –¥–ª—è –ª—É—á—à–µ–≥–æ –∫–∞—á–µ—Å—Ç–≤–∞)
        """
        self.client = openai.OpenAI(api_key=api_key)
        self.model = model

    def extract_documents(self, text: str) -> Dict[str, List[Dict[str, Any]]]:
        """
        –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –∏–∑ —Ç–µ–∫—Å—Ç–∞ —Å —É–ª—É—á—à–µ–Ω–∏—è–º–∏
        
        Args:
            text: –¢–µ–∫—Å—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
            
        Returns:
            –°–ª–æ–≤–∞—Ä—å —Å –∏–∑–≤–ª–µ—á–µ–Ω–Ω—ã–º–∏ –¥–æ–∫—É–º–µ–Ω—Ç–∞–º–∏ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º
        """
        # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º —Ä–∞–∑–º–µ—Ä —á–∞–Ω–∫–∞ –¥–ª—è –ª—É—á—à–µ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏
        max_chunk_size = 5000
        text_chunks = self._split_text(text, max_chunk_size)
        all_documents = []

        # –ö–†–ò–¢–ò–ß–ï–°–ö–û–ï –£–õ–£–ß–®–ï–ù–ò–ï: –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –í–°–ï —á–∞–Ω–∫–∏, –∞ –Ω–µ —Ç–æ–ª—å–∫–æ –ø–µ—Ä–≤—ã–µ 3
        print(f"üìÑ –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º {len(text_chunks)} —á–∞–Ω–∫–æ–≤ (–≤—Å–µ)")
        
        for i, chunk in enumerate(text_chunks, 1):
            try:
                print(f"üîÑ –ß–∞–Ω–∫ {i}/{len(text_chunks)}", end=" ")
                chunk_docs = self._process_chunk(chunk)
                all_documents.extend(chunk_docs)
                print(f"‚úÖ({len(chunk_docs)})")
                
                # –ü–∞—É–∑–∞ –º–µ–∂–¥—É –∑–∞–ø—Ä–æ—Å–∞–º–∏ –¥–ª—è –∏–∑–±–µ–∂–∞–Ω–∏—è rate limits
                time.sleep(0.5)
            except Exception as e:
                print(f"‚ùå({str(e)[:20]})")
                continue

        # –£–¥–∞–ª—è–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã
        unique_documents = self._remove_duplicates(all_documents)

        # –†–∞–∑–¥–µ–ª—è–µ–º –Ω–∞ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏
        npa_docs = []
        letter_docs = []

        for doc in unique_documents:
            doc_type = doc.get('type', '').lower()
            if '–ø–∏—Å—å–º–æ' in doc_type or doc.get('category') == '–ü–ò–°–¨–ú–û':
                letter_docs.append(doc)
            else:
                npa_docs.append(doc)

        return {
            'all_documents': unique_documents,
            'npa_documents': npa_docs,
            'letters': letter_docs
        }

    def _process_chunk(self, chunk: str) -> List[Dict[str, Any]]:
        """
        –û–±—Ä–∞–±–æ—Ç–∫–∞ –æ–¥–Ω–æ–≥–æ —á–∞–Ω–∫–∞ —Ç–µ–∫—Å—Ç–∞ —Å —É–ª—É—á—à–µ–Ω–Ω—ã–º –ø—Ä–æ–º–ø—Ç–æ–º
        
        Args:
            chunk: –§—Ä–∞–≥–º–µ–Ω—Ç —Ç–µ–∫—Å—Ç–∞ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏
            
        Returns:
            –°–ø–∏—Å–æ–∫ –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
        """
        # –£–õ–£–ß–®–ï–ù–ù–´–ô –ü–†–û–ú–ü–¢: –±–æ–ª–µ–µ —Ç–æ—á–Ω—ã–µ –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏ –∏ –ø—Ä–∏–º–µ—Ä—ã
        prompt = f"""
        –ù–∞–π–¥–∏ –≤ —Ç–µ–∫—Å—Ç–µ –í–°–ï —Ä–æ—Å—Å–∏–π—Å–∫–∏–µ –ø—Ä–∞–≤–æ–≤—ã–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã. –ë—É–¥—å –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ –≤–Ω–∏–º–∞—Ç–µ–ª—å–Ω—ã–º!

        –¢–ò–ü–´ –î–û–ö–£–ú–ï–ù–¢–û–í –î–õ–Ø –ü–û–ò–°–ö–ê:
        - –§–µ–¥–µ—Ä–∞–ª—å–Ω—ã–µ –∑–∞–∫–æ–Ω—ã (–ø—Ä–∏–º–µ—Ä—ã: ‚Ññ273-–§–ó, 323-–§–ó, 426-–§–ó, 477–Ω)
        - –ü–æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—è –ü—Ä–∞–≤–∏—Ç–µ–ª—å—Å—Ç–≤–∞ (–ø—Ä–∏–º–µ—Ä—ã: ‚Ññ1490, 825, 580, 719)
        - –ü—Ä–∏–∫–∞–∑—ã –º–∏–Ω–∏—Å—Ç–µ—Ä—Å—Ç–≤ (–ø—Ä–∏–º–µ—Ä—ã: ‚Ññ709–Ω, 816, 477–Ω, 205, 947–Ω)
        - –ü–ò–°–¨–ú–ê –≤—Å–µ—Ö –≤–∏–¥–æ–≤ (–ø—Ä–∏–º–µ—Ä—ã: –ê–ö-1879/06, 14-0/10/–í-2253, 06-735)
        - –£–∫–∞–∑—ã, –ø–æ–ª–æ–∂–µ–Ω–∏—è, —Ä–µ–≥–ª–∞–º–µ–Ω—Ç—ã, —Å—Ç–∞–Ω–¥–∞—Ä—Ç—ã

        –í–ê–ñ–ù–´–ï –ü–†–ê–í–ò–õ–ê:
        - –í–∫–ª—é—á–∞–π –í–°–ï –¥–æ–∫—É–º–µ–Ω—Ç—ã —Å –Ω–æ–º–µ—Ä–∞–º–∏ (–¥–∞–∂–µ 477–Ω, 205, 806)
        - –ù–ï –ø—Ä–æ–ø—É—Å–∫–∞–π –¥–æ–∫—É–º–µ–Ω—Ç—ã –±–µ–∑ —É–∫–∞–∑–∞–Ω–∏—è –≤–µ–¥–æ–º—Å—Ç–≤–∞
        - –ò—â–∏ –≤ —Å–ø–∏—Å–∫–∞—Ö, —Ç–∞–±–ª–∏—Ü–∞—Ö, —Å–ø–ª–æ—à–Ω–æ–º —Ç–µ–∫—Å—Ç–µ
        - –ò–∑–≤–ª–µ–∫–∞–π —Ç–æ—á–Ω—ã–µ –Ω–æ–º–µ—Ä–∞ –∏ –ø–æ–ª–Ω—ã–µ –Ω–∞–∑–≤–∞–Ω–∏—è

        –ò–ì–ù–û–†–ò–†–£–ô —Ç–æ–ª—å–∫–æ:
        - HTTP —Å—Å—ã–ª–∫–∏ –∏ URL
        - –¢–µ–ª–µ—Ñ–æ–Ω—ã –∏ –ø–æ—á—Ç–æ–≤—ã–µ –∞–¥—Ä–µ—Å–∞
        - –ù–æ–º–µ—Ä–∞ —Å—Ç—Ä–∞–Ω–∏—Ü –∏ —Ä–∞–∑–¥–µ–ª–æ–≤

        –í–µ—Ä–Ω–∏ JSON —Å–æ –í–°–ï–ú–ò –Ω–∞–π–¥–µ–Ω–Ω—ã–º–∏ –¥–æ–∫—É–º–µ–Ω—Ç–∞–º–∏:
        {{
            "documents": [
                {{
                    "type": "—Ç–æ—á–Ω—ã–π —Ç–∏–ø –¥–æ–∫—É–º–µ–Ω—Ç–∞",
                    "number": "—Ç–æ—á–Ω—ã–π –Ω–æ–º–µ—Ä",
                    "title": "–ø–æ–ª–Ω–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç–∞",
                    "category": "–ù–ü–ê" –∏–ª–∏ "–ü–ò–°–¨–ú–û"
                }}
            ]
        }}

        –¢–µ–∫—Å—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞:
        {chunk[:4500]}
        """

        try:
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[{"role": "user", "content": prompt}],
                temperature=0.1,  # –Ω–∏–∑–∫–∞—è —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞ –¥–ª—è —Ç–æ—á–Ω–æ—Å—Ç–∏
                max_tokens=2000   # —É–≤–µ–ª–∏—á–µ–Ω–æ –¥–ª—è –±–æ–ª—å—à–µ–≥–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
            )

            result = response.choices[0].message.content
            
            # –ë–æ–ª–µ–µ –Ω–∞–¥–µ–∂–Ω—ã–π –ø–∞—Ä—Å–∏–Ω–≥ JSON
            json_start = result.find('{')
            json_end = result.rfind('}') + 1

            if json_start != -1 and json_end != -1:
                json_str = result[json_start:json_end]
                try:
                    chunk_data = json.loads(json_str)
                    documents = chunk_data.get('documents', [])
                    
                    # –ë–∞–∑–æ–≤–∞—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è –æ—Ç –º—É—Å–æ—Ä–∞
                    valid_docs = []
                    for doc in documents:
                        if self._is_valid_document(doc):
                            valid_docs.append(doc)
                    
                    return valid_docs
                except json.JSONDecodeError:
                    # –ü–æ–ø—ã—Ç–∫–∞ –∏—Å–ø—Ä–∞–≤–∏—Ç—å JSON
                    try:
                        # –£–±–∏—Ä–∞–µ–º –≤–æ–∑–º–æ–∂–Ω—ã–µ –ø—Ä–æ–±–ª–µ–º—ã —Å –∫–∞–≤—ã—á–∫–∞–º–∏
                        fixed_json = json_str.replace('\\"', '"').replace('\\n', ' ')
                        chunk_data = json.loads(fixed_json)
                        return chunk_data.get('documents', [])
                    except:
                        return []

        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —á–∞–Ω–∫–∞: {e}")
            return []

        return []

    def _is_valid_document(self, doc: Dict[str, Any]) -> bool:
        """
        –ü—Ä–æ–≤–µ—Ä–∫–∞ –≤–∞–ª–∏–¥–Ω–æ—Å—Ç–∏ –¥–æ–∫—É–º–µ–Ω—Ç–∞
        
        Args:
            doc: –î–æ–∫—É–º–µ–Ω—Ç –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏
            
        Returns:
            True –µ—Å–ª–∏ –¥–æ–∫—É–º–µ–Ω—Ç –≤–∞–ª–∏–¥–µ–Ω
        """
        number = str(doc.get('number', '')).strip()
        title = str(doc.get('title', '')).strip().lower()
        
        # –ò—Å–∫–ª—é—á–∞–µ–º —Ç–æ–ª—å–∫–æ –æ—á–µ–≤–∏–¥–Ω—ã–π –º—É—Å–æ—Ä
        if (not number or 
            number in ['', 'nan', 'none', '–Ω–µ—Ç', '–Ω/–∞'] or
            len(number) > 30 or
            'http' in title or
            'www' in title or
            '@' in title or
            len(title) < 5):
            return False
        
        # –í—Å–µ –æ—Å—Ç–∞–ª—å–Ω–æ–µ —Å—á–∏—Ç–∞–µ–º –≤–∞–ª–∏–¥–Ω—ã–º
        return True

    def _split_text(self, text: str, max_size: int) -> List[str]:
        """
        –†–∞–∑–±–∏–≤–∫–∞ —Ç–µ–∫—Å—Ç–∞ –Ω–∞ —á–∞–Ω–∫–∏ —Å —É–ª—É—á—à–µ–Ω–Ω–æ–π –ª–æ–≥–∏–∫–æ–π
        
        Args:
            text: –ò—Å—Ö–æ–¥–Ω—ã–π —Ç–µ–∫—Å—Ç
            max_size: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä —á–∞–Ω–∫–∞
            
        Returns:
            –°–ø–∏—Å–æ–∫ —á–∞–Ω–∫–æ–≤ —Ç–µ–∫—Å—Ç–∞
        """
        if len(text) <= max_size:
            return [text]

        chunks = []
        start = 0
        overlap = 500  # –ø–µ—Ä–µ–∫—Ä—ã—Ç–∏–µ –º–µ–∂–¥—É —á–∞–Ω–∫–∞–º–∏

        while start < len(text):
            end = start + max_size
            
            if end >= len(text):
                # –ü–æ—Å–ª–µ–¥–Ω–∏–π —á–∞–Ω–∫
                chunks.append(text[start:])
                break
            
            # –ò—â–µ–º —É–¥–æ–±–Ω–æ–µ –º–µ—Å—Ç–æ –¥–ª—è —Ä–∞–∑—Ä—ã–≤–∞
            chunk = text[start:end]
            
            # –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç —Ä–∞–∑—Ä—ã–≤–∞: –¥–≤–æ–π–Ω–æ–π –ø–µ—Ä–µ–Ω–æ—Å > –æ–¥–∏–Ω–∞—Ä–Ω—ã–π > —Ç–æ—á–∫–∞ > –ø—Ä–æ–±–µ–ª
            break_points = [
                chunk.rfind('\n\n'),
                chunk.rfind('\n'),
                chunk.rfind('. '),
                chunk.rfind(' ')
            ]
            
            best_break = -1
            for bp in break_points:
                if bp > max_size - 300:  # –Ω–µ —Å–ª–∏—à–∫–æ–º –±–ª–∏–∑–∫–æ –∫ –∫–æ–Ω—Ü—É
                    best_break = bp
                    break
            
            if best_break > 0:
                actual_end = start + best_break + 1
                chunks.append(text[start:actual_end])
                start = actual_end - overlap  # —Å –ø–µ—Ä–µ–∫—Ä—ã—Ç–∏–µ–º
            else:
                # –ï—Å–ª–∏ –Ω–µ –Ω–∞—à–ª–∏ —Ö–æ—Ä–æ—à–µ–µ –º–µ—Å—Ç–æ, —Ä–∞–∑—Ä—ã–≤–∞–µ–º –ø–æ —Ä–∞–∑–º–µ—Ä—É
                chunks.append(chunk)
                start = end - overlap

        return chunks

    def _remove_duplicates(self, documents: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """
        –£–¥–∞–ª–µ–Ω–∏–µ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ —Å —É–ª—É—á—à–µ–Ω–Ω–æ–π –ª–æ–≥–∏–∫–æ–π
        
        Args:
            documents: –°–ø–∏—Å–æ–∫ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
            
        Returns:
            –°–ø–∏—Å–æ–∫ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
        """
        seen = {}
        unique_docs = []

        for doc in documents:
            # –°–æ–∑–¥–∞–µ–º –∫–ª—é—á –¥–ª—è –¥–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏–∏
            doc_type = doc.get('type', '').lower().strip()
            doc_number = str(doc.get('number', '')).lower().strip()
            
            # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –Ω–æ–º–µ—Ä –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
            import re
            clean_number = re.sub(r'[‚Ññn¬∞#\s\-_]+', '', doc_number)
            
            key = f"{doc_type}_{clean_number}"
            
            if key not in seen:
                seen[key] = doc
                unique_docs.append(doc)
            else:
                # –ï—Å–ª–∏ –¥—É–±–ª–∏–∫–∞—Ç, –≤—ã–±–∏—Ä–∞–µ–º –¥–æ–∫—É–º–µ–Ω—Ç —Å –±–æ–ª–µ–µ –ø–æ–ª–Ω—ã–º –Ω–∞–∑–≤–∞–Ω–∏–µ–º
                existing_doc = seen[key]
                current_title_len = len(doc.get('title', ''))
                existing_title_len = len(existing_doc.get('title', ''))
                
                if current_title_len > existing_title_len:
                    # –ó–∞–º–µ–Ω—è–µ–º –≤ —Å–ø–∏—Å–∫–µ
                    for i, item in enumerate(unique_docs):
                        if item == existing_doc:
                            unique_docs[i] = doc
                            seen[key] = doc
                            break

        return unique_docs
